{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:\n",
      "recommendation 1 : 3607\n",
      "recommendation 2 : 891\n",
      "recommendation 3 : 614\n",
      "recommendation 4 : 414\n",
      "recommendation 5 : 324\n",
      "rf map5: 0.4425466666666667\n",
      "XGBoost:\n",
      "recommendation 1 : 3081\n",
      "recommendation 2 : 953\n",
      "recommendation 3 : 635\n",
      "recommendation 4 : 462\n",
      "recommendation 5 : 361\n",
      "xgb map5: 0.39568666666666663\n",
      "adaboost:\n",
      "recommendation 1 : 3767\n",
      "recommendation 2 : 837\n",
      "recommendation 3 : 549\n",
      "recommendation 4 : 381\n",
      "recommendation 5 : 291\n",
      "ada map5: 0.45219499999999996\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForest:\")\n",
    "print(\"rf map5:\",map5eval(rf_preds[20000:30000],y_test[20000:30000]))\n",
    "print(\"XGBoost:\")\n",
    "print(\"xgb map5:\",map5eval(xgb_preds[20000:30000],y_test[20000:30000]))\n",
    "print(\"adaboost:\")\n",
    "print(\"ada map5:\",map5eval(ada_preds[20000:30000],y_test[20000:30000]))\n",
    "# print(\"RandomForest:\")\n",
    "# print(\"rf map5:\",map5eval(rf_preds,y_test))\n",
    "# print(\"XGBoost:\")\n",
    "# print(\"xgb map5:\",map5eval(xgb_preds,y_test))\n",
    "# print(\"adaboost:\")\n",
    "# print(\"ada map5:\",map5eval(ada_preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def map5eval(preds, actual):\n",
    "    predicted = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        predicted.append(preds[i].argsort()[-5:][::-1])\n",
    "    predicted = np.array(predicted)\n",
    "    metric = 0.\n",
    "    for i in range(5):\n",
    "        metric += np.sum(actual==predicted[:,i])/(i+1)\n",
    "        print(\"recommendation\",i+1,\":\",np.sum(actual==predicted[:,i]))\n",
    "    metric /= actual.shape[0]\n",
    "    return metric\n",
    "\n",
    "def map5eval2(predicted, actual):\n",
    "    metric = 0.\n",
    "    for i in range(5):\n",
    "        metric += np.sum(actual==predicted[:,i])/(i+1)\n",
    "#         print(\"recommendation\",i+1,\":\",np.sum(actual==predicted[:,i]))\n",
    "    metric /= actual.shape[0]\n",
    "    return metric\n",
    "\n",
    "xgb_preds = []\n",
    "with open(\"XGB_PREDICTIONS_2\",\"rb\") as file:\n",
    "    # xgb_preds = pickle.load(file)\n",
    "    xgb_preds = pickle.load(file)\n",
    "rf_preds = []\n",
    "with open(\"RF_PREDICTIONS_FINALLL\",\"rb\") as file:\n",
    "    rf_preds = pickle.load(file)\n",
    "ada_preds = []\n",
    "with open(\"ADA_PREDICTIONS_md_20_nest_500\",\"rb\") as file:\n",
    "\tada_preds = pickle.load(file)\n",
    "y_test = []\n",
    "with open(\"y_test\",\"rb\") as file:\n",
    "    y_test = np.array(pickle.load(file))\n",
    "\n",
    "# w1 = 2.3 # rf weight - 4.2: 0.4542 --> 4.23\n",
    "# w2 = 2 # xgb weight - 2: 0.455\n",
    "# w3 = 2.5 # ada weight\n",
    "# w1 = 2.5\n",
    "# w2 = 1.5\n",
    "# w3 = 4\n",
    "import time\n",
    "tm=0\n",
    "wm=[]\n",
    "weights = []\n",
    "test_map5s = []\n",
    "train_map5s = []\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "rf_preds2 = rf_preds\n",
    "xgb_preds2 = xgb_preds\n",
    "ada_preds2 = ada_preds\n",
    "for train_index, test_index in sss.split(rf_preds2,y_test):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    w1 = 2\n",
    "    w2 = 3\n",
    "    w3 = 6\n",
    "#     rf_preds, y_preds = rf_preds2[train_index], y_test[test_index]\n",
    "#     xgb_preds, y_preds2 = xgb_preds2[train_index], y_test[test_index]\n",
    "#     ada_preds, y_preds3 = ada_preds2[train_index], y_test[test_index]\n",
    "    finprobs = []\n",
    "    for i in train_index:\n",
    "        p1 = rf_preds[i].argsort()[-5:][::-1]\n",
    "        p2 = xgb_preds[i].argsort()[-5:][::-1]\n",
    "        p3 = ada_preds[i].argsort()[-5:][::-1]\n",
    "        p1_scores = sorted(rf_preds[i])[-5:][::-1]\n",
    "        p2_scores = sorted(xgb_preds[i])[-5:][::-1]\n",
    "        p3_scores = sorted(ada_preds[i])[-5:][::-1]\n",
    "        probs = [0]*100\n",
    "        for k in range(5):\n",
    "            if p1[k]==p2[k] and p1[k] == p3[k]:\n",
    "                probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "            elif p1[k]==p2[k]:\n",
    "                probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k])\n",
    "                probs[p3[k]] += (w3*p3_scores[k])\n",
    "            elif p2[k]==p3[k]:\n",
    "                probs[p2[k]] += (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "                probs[p1[k]] += (w1*p1_scores[k])\n",
    "            elif p1[k]==p3[k]:\n",
    "                probs[p1[k]] += (w1*p1_scores[k]) + (w3*p3_scores[k])\n",
    "                probs[p2[k]] += (w2*p2_scores[k])\n",
    "            else:\n",
    "                probs[p1[k]] += (w1*p1_scores[k])\n",
    "                probs[p2[k]] += (w2*p2_scores[k])\n",
    "                probs[p3[k]] += (w3*p3_scores[k])\n",
    "\n",
    "        probs = np.array(probs).argsort()[-5:][::-1]\n",
    "        finprobs.append(probs)\n",
    "    trmap5 = map5eval2(np.array(finprobs),y_test[train_index])\n",
    "    print(\"train ensemble map5:\",trmap5)\n",
    "    print(np.array(finprobs).shape,y_test[train_index].shape)\n",
    "    finprobs = []\n",
    "    for i in test_index:\n",
    "        p1 = rf_preds[i].argsort()[-5:][::-1]\n",
    "        p2 = xgb_preds[i].argsort()[-5:][::-1]\n",
    "        p3 = ada_preds[i].argsort()[-5:][::-1]\n",
    "        p1_scores = sorted(rf_preds[i])[-5:][::-1]\n",
    "        p2_scores = sorted(xgb_preds[i])[-5:][::-1]\n",
    "        p3_scores = sorted(ada_preds[i])[-5:][::-1]\n",
    "        probs = [0]*100\n",
    "        for k in range(5):\n",
    "            if p1[k]==p2[k] and p1[k] == p3[k]:\n",
    "                probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "            elif p1[k]==p2[k]:\n",
    "                probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k])\n",
    "                probs[p3[k]] += (w3*p3_scores[k])\n",
    "            elif p2[k]==p3[k]:\n",
    "                probs[p2[k]] += (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "                probs[p1[k]] += (w1*p1_scores[k])\n",
    "            elif p1[k]==p3[k]:\n",
    "                probs[p1[k]] += (w1*p1_scores[k]) + (w3*p3_scores[k])\n",
    "                probs[p2[k]] += (w2*p2_scores[k])\n",
    "            else:\n",
    "                probs[p1[k]] += (w1*p1_scores[k])\n",
    "                probs[p2[k]] += (w2*p2_scores[k])\n",
    "                probs[p3[k]] += (w3*p3_scores[k])\n",
    "\n",
    "        probs = np.array(probs).argsort()[-5:][::-1]\n",
    "        finprobs.append(probs)\n",
    "    tmap5 = map5eval2(np.array(finprobs),y_test[train_index])\n",
    "    if tmap5 > tm:\n",
    "        tm = tmap5\n",
    "        wm = [w1,w2,w3]\n",
    "    weights.append([w1,w2,w3])\n",
    "    test_map5s.append(tmap5)\n",
    "    train_map5s.append(trmap5)\n",
    "    print(np.array(finprobs).shape,y_test[test_index].shape)\n",
    "    print(\"test ensemble map5:\",map5eval2(np.array(finprobs),y_test[test_index]))\n",
    "    print(\"RandomForest:\")\n",
    "    print(\"rf map5:\",map5eval(rf_preds[test_index],y_test[test_index]))\n",
    "    print(\"XGBoost:\")\n",
    "    print(\"xgb map5:\",map5eval(xgb_preds[test_index],y_test[test_index]))\n",
    "    print(\"adaboost:\")\n",
    "    print(\"ada map5:\",map5eval(ada_preds[test_index],y_test[test_index]))\n",
    "    print(\"------\")\n",
    "print(wm,tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting scheme - RandomForest, XGBoost, AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest:\n",
    "recommendation 1 : 10985\n",
    "recommendation 2 : 2695\n",
    "recommendation 3 : 1843\n",
    "recommendation 4 : 1308\n",
    "recommendation 5 : 967\n",
    "rf map5: 0.4489077777777778\n",
    "XGBoost:\n",
    "recommendation 1 : 9420\n",
    "recommendation 2 : 2857\n",
    "recommendation 3 : 1908\n",
    "recommendation 4 : 1366\n",
    "recommendation 5 : 1066\n",
    "xgb map5: 0.4013066666666667\n",
    "adaboost:\n",
    "recommendation 1 : 11529\n",
    "recommendation 2 : 2497\n",
    "recommendation 3 : 1613\n",
    "recommendation 4 : 1104\n",
    "recommendation 5 : 884\n",
    "ada map5: 0.4589322222222222\n",
    "Ensemble:\n",
    "recommendation 1 : 11445\n",
    "recommendation 2 : 2739\n",
    "recommendation 3 : 1676\n",
    "recommendation 4 : 1316\n",
    "recommendation 5 : 915\n",
    "ensemble map5: 0.46283888888888886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation 1 : 3081\n",
      "recommendation 2 : 953\n",
      "recommendation 3 : 635\n",
      "recommendation 4 : 462\n",
      "recommendation 5 : 361\n",
      "xgb map5: 0.39568666666666663\n",
      "w1: 2 w2: 3 w3: 6\n",
      "recommendation 1 : 3802\n",
      "recommendation 2 : 882\n",
      "recommendation 3 : 542\n",
      "recommendation 4 : 398\n",
      "recommendation 5 : 320\n",
      "map5: 0.4587166666666667\n",
      "recommendation 1 : 7776\n",
      "recommendation 2 : 1785\n",
      "recommendation 3 : 1095\n",
      "recommendation 4 : 808\n",
      "recommendation 5 : 601\n",
      "map5: 0.46778500000000006\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def map5eval(preds, actual):\n",
    "    predicted = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        predicted.append(preds[i].argsort()[-5:][::-1])\n",
    "    predicted = np.array(predicted)\n",
    "    metric = 0.\n",
    "    for i in range(5):\n",
    "        metric += np.sum(actual==predicted[:,i])/(i+1)\n",
    "        print(\"recommendation\",i+1,\":\",np.sum(actual==predicted[:,i]))\n",
    "    metric /= actual.shape[0]\n",
    "    return metric\n",
    "\n",
    "def map5eval2(predicted, actual):\n",
    "    metric = 0.\n",
    "    for i in range(5):\n",
    "        metric += np.sum(actual==predicted[:,i])/(i+1)\n",
    "        print(\"recommendation\",i+1,\":\",np.sum(actual==predicted[:,i]))\n",
    "    metric /= actual.shape[0]\n",
    "    return metric\n",
    "\n",
    "xgb_preds = []\n",
    "with open(\"XGB_PREDICTIONS_2\",\"rb\") as file:\n",
    "    # xgb_preds = pickle.load(file)\n",
    "    xgb_preds = pickle.load(file)\n",
    "rf_preds = []\n",
    "with open(\"RF_PREDICTIONS_FINALLL\",\"rb\") as file:\n",
    "    rf_preds = pickle.load(file)\n",
    "ada_preds = []\n",
    "with open(\"ADA_PREDICTIONS_md_20_nest_500\",\"rb\") as file:\n",
    "\tada_preds = pickle.load(file)\n",
    "y_test = []\n",
    "with open(\"y_test\",\"rb\") as file:\n",
    "    y_test = np.array(pickle.load(file))\n",
    "\n",
    "# print(\"RandomForest:\")\n",
    "# print(\"rf map5:\",map5eval(rf_preds,y_test))\n",
    "# print(\"XGBoost:\")\n",
    "# print(\"xgb map5:\",map5eval(xgb_preds,y_test))\n",
    "# print(\"adaboost:\")\n",
    "# print(\"ada map5:\",map5eval(ada_preds,y_test))\n",
    "# w1 = 2.3 # rf weight - 4.2: 0.4542 --> 4.23\n",
    "# w2 = 2 # xgb weight - 2: 0.455\n",
    "# w3 = 2.5 # ada weight\n",
    "# w = [[3,4,6],[3,4,7],[3,4,8],[3,4,9],[3,4,10],[3,4,11],[3,4,12],[3,4,13]]\n",
    "# print(\"xgb map5:\",map5eval(xgb_preds[20000:30000],y_test[20000:30000]))\n",
    "w1 = 2\n",
    "w2 = 3\n",
    "w3 = 6\n",
    "print(\"w1:\",w1,\"w2:\",w2,\"w3:\",w3)\n",
    "finprobs=[]\n",
    "test_ops = []\n",
    "test_preds = []\n",
    "for i in range(20000,30000):\n",
    "    p1 = rf_preds[i].argsort()[-5:][::-1]\n",
    "    p2 = xgb_preds[i].argsort()[-5:][::-1]\n",
    "    p3 = ada_preds[i].argsort()[-5:][::-1]\n",
    "    p1_scores = sorted(rf_preds[i])[-5:][::-1]\n",
    "    p2_scores = sorted(xgb_preds[i])[-5:][::-1]\n",
    "    p3_scores = sorted(ada_preds[i])[-5:][::-1]\n",
    "    l = []\n",
    "    l.extend(p1)\n",
    "    l.extend(p2)\n",
    "    l.extend(p3)\n",
    "    l.extend(p1_scores)\n",
    "    l.extend(p2_scores)\n",
    "    l.extend(p3_scores)\n",
    "    \n",
    "    test_preds.append(l)\n",
    "    test_ops.append(int(y_test[i]))\n",
    "    probs = [0]*100\n",
    "    for k in range(5):\n",
    "        if p1[k]==p2[k] and p1[k] == p3[k]:\n",
    "            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "        elif p1[k]==p2[k]:\n",
    "            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k])\n",
    "            probs[p3[k]] += (w3*p3_scores[k])\n",
    "        elif p2[k]==p3[k]:\n",
    "            probs[p2[k]] += (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "            probs[p1[k]] += (w1*p1_scores[k])\n",
    "        elif p1[k]==p3[k]:\n",
    "            probs[p1[k]] += (w1*p1_scores[k]) + (w3*p3_scores[k])\n",
    "            probs[p2[k]] += (w2*p2_scores[k])\n",
    "        else:\n",
    "            probs[p1[k]] += (w1*p1_scores[k])\n",
    "            probs[p2[k]] += (w2*p2_scores[k])\n",
    "            probs[p3[k]] += (w3*p3_scores[k])\n",
    "\n",
    "    probs = np.array(probs).argsort()[-5:][::-1]\n",
    "    finprobs.append(probs)\n",
    "trmap5 = map5eval2(np.array(finprobs),y_test[20000:30000])\n",
    "print(\"map5:\",trmap5)\n",
    "finprobs = []\n",
    "train_preds = []\n",
    "train_ops = []\n",
    "for i in range(20000):\n",
    "    p1 = rf_preds[i].argsort()[-5:][::-1]\n",
    "    p2 = xgb_preds[i].argsort()[-5:][::-1]\n",
    "    p3 = ada_preds[i].argsort()[-5:][::-1]\n",
    "    p1_scores = sorted(rf_preds[i])[-5:][::-1]\n",
    "    p2_scores = sorted(xgb_preds[i])[-5:][::-1]\n",
    "    p3_scores = sorted(ada_preds[i])[-5:][::-1]\n",
    "    l = []\n",
    "    l.extend(p1)\n",
    "    l.extend(p2)\n",
    "    l.extend(p3)\n",
    "    l.extend(p1_scores)\n",
    "    l.extend(p2_scores)\n",
    "    l.extend(p3_scores)\n",
    "    \n",
    "    train_preds.append(l)\n",
    "    train_ops.append(int(y_test[i]))\n",
    "    probs = [0]*100\n",
    "    for k in range(5):\n",
    "        if p1[k]==p2[k] and p1[k] == p3[k]:\n",
    "            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "        elif p1[k]==p2[k]:\n",
    "            probs[p1[k]] += (w1*p1_scores[k]) + (w2*p2_scores[k])\n",
    "            probs[p3[k]] += (w3*p3_scores[k])\n",
    "        elif p2[k]==p3[k]:\n",
    "            probs[p2[k]] += (w2*p2_scores[k]) + (w3*p3_scores[k])\n",
    "            probs[p1[k]] += (w1*p1_scores[k])\n",
    "        elif p1[k]==p3[k]:\n",
    "            probs[p1[k]] += (w1*p1_scores[k]) + (w3*p3_scores[k])\n",
    "            probs[p2[k]] += (w2*p2_scores[k])\n",
    "        else:\n",
    "            probs[p1[k]] += (w1*p1_scores[k])\n",
    "            probs[p2[k]] += (w2*p2_scores[k])\n",
    "            probs[p3[k]] += (w3*p3_scores[k])\n",
    "\n",
    "    probs = np.array(probs).argsort()[-5:][::-1]\n",
    "    finprobs.append(probs)\n",
    "trmap5 = map5eval2(np.array(finprobs),y_test[:20000])\n",
    "print(\"map5:\",trmap5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1: 1 w2: 1 w3: 1\n",
    "# map5: 0.46283888888888886\n",
    "# to beat: 0.4589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 20000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_preds[0]),len(train_ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_preds[0]),len(test_ops))\n",
    "def map5eval(preds, actual):\n",
    "    predicted = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        predicted.append(preds[i].argsort()[-5:][::-1])\n",
    "    predicted = np.array(predicted)\n",
    "    metric = 0.\n",
    "    for i in range(5):\n",
    "        metric += np.sum(actual==predicted[:,i])/(i+1)\n",
    "#         print(\"recommendation\",i+1,\":\",np.sum(actual==predicted[:,i]))\n",
    "    metric /= actual.shape[0]\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting RF model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=36, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=36,n_estimators=300, n_jobs=-1, warm_start=True)\n",
    "op = np.array(train_ops)\n",
    "tr = np.array(train_preds)\n",
    "print(\"fitting RF model...\")\n",
    "clf.fit(tr[:15000],op[:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40545"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map5eval(clf.predict_proba(np.array(train_preds[15000:20000])),np.array(train_ops[15000:20000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4506"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map5eval(rf_preds[15000:20000],np.array(train_ops[15000:20000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting..\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 13.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['lbfgs']},\n",
    "    {'classifier' : [RandomForestClassifier(max_depth=10,n_estimators=100, n_jobs=-1, warm_start=True)],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "]\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(tr[:12000],op[:12000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation 1 : 2866\n",
      "recommendation 2 : 387\n",
      "recommendation 3 : 285\n",
      "recommendation 4 : 243\n",
      "recommendation 5 : 183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40648125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map5eval(best_clf.predict_proba(np.array(train_preds[12000:])),np.array(train_ops[12000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3982716666666667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map5eval(best_clf.predict_proba(np.array(test_preds)),np.array(test_ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4425466666666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map5eval(rf_preds[20000:30000],np.array(test_ops))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
